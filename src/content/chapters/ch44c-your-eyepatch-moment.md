# Chapter 44: Your eyepatch moment

_Part 4_

My twin boys play a game with me when we’re watching the telly, we have to guess the brand before the ad ends. Last night, 8:30 break, three of us actually paying attention, kettle clicking in the background, and we still had nothing when the last frame faded out. We all lost.


If you know marketing, you already know what the diagnosis is. Distinctive brand assets are the table stakes. Jenni Romaniuk has spent a career putting the academic foundations under the plain truth, people notice and remember the consistent bits, the cues, the shortcuts, not your strategy doc or your new “look and feel”. (Romaniuk, Building Distinctive Brand Assets.)
The part that’s changed is the tools. AI does not create distinctiveness. It repeats, it blends, it spits out more. It makes whatever you feed it show up in more places, in more shapes, at more speed. If what you feed it is a clear, consistent asset, you get more of that clarity, every day, across formats you used to avoid because they were a pain. If what you feed it is vague, or you keep changing your cues because you’re bored, you get average everywhere, quicker than ever.
The Hathaway eyepatch is the cleanest story here because it’s so unromantic. Ogilvy bought it on the way to the photoshoot in 1951, it cost fifty cents, and it ended up on a model who looked like he’d actually lived a life. It became one of the most recognised assets in advertising history for the dull reason, they kept using it. The eyepatch only works because Hathaway didn’t replace it with a monocle the following year.
That is the bit most brands miss. They think the hard work is “find your eyepatch.” For most brands, the hard work is noticing what they already have, then having the discipline to stop taking it off.
You can see the proof in work that was built long before anyone was typing prompts. In 2021, we ran a National Lottery campaign built around the waterslide. Show Irish adults the waterslide with the logo, name, and tagline removed, and 72% can still spontaneously name the brand. (National Lottery waterslide, 2021.) That number only happens when the cue has been repeated enough times that the brain stops needing help.
It also solved a real constraint that has nothing to do with taste. Karen Nelson-Field’s research shows you get about two to three seconds on Facebook before attention drops. (Nelson-Field.) If the brand is not obvious by then, the ad might as well not exist, even if it’s beautifully made. The waterslide let us stop stuffing the name into the first frame like a legal warning and start making the ads enjoyable. I remember thinking, “We set out to do this but I thought it might take longer.” (National Lottery waterslide, 2021.) Repetition is meant to be boring. It is also meant to work.
Now take that same kind of cue and imagine what the tools let you do with it. Not “make more ads.” Make the same recognisable thing turn up in the right context, in the right format, every day. A six-second cut when the match is on. A static when it’s raining sideways and the mood is different. A vertical story when the platform shifts again. The point is not novelty. The point is presence, without needing a writing room and a production army to rebuild the same thing from scratch each time.
O2’s Bubl is the example that stops this turning into AI daydreaming. They used Bubl consistently for over four years. (VCCP and faith, Bubl Generator case study.) Then marketers tried to DIY Bubl imagery with off-the-shelf AI tools, and consistency broke down. That’s not a scandal, it’s the default. The tools are good at variation, and humans are good at convincing themselves “close enough” is fine when they’re rushing.
So VCCP’s AI agency, faith, built infrastructure, the Bubl Generator. (VCCP and faith.) It took multiple rounds of training before the AI could consistently create high-quality, usable images. They needed a 3D model of Bubl so the system could be trained on poses that didn’t exist before, because “previously, Bubl had only been seen from the front.” (VCCP and faith.) The result was practical, “The character can be used in channels where cost or time constraints previously limited its use.” (VCCP and faith.) Not zero effort. Real work, in service of consistency.
That’s the intersection this chapter is about. Fundamentals and tools, together. The fundamental is knowing what people actually recognise. Not what the team likes, not what the CMO is newly obsessed with, not what the agency wants to win awards for this year. The tool is AI, which can now help you keep that recognisable cue intact while you generate the daily pile of formats, versions, and reactive moments that used to chew up teams.
If you only have the tool, you get a higher volume of “who is this for” and “what brand is that,” which is a grim achievement. If you only have the asset, you still struggle to show up in all the places you need to, especially when the ask is constant and the timelines are stupid. If you have both, you can make the cue show up everywhere it matters, in context, without each execution turning into a fresh debate about brand.
Most brands already have an eyepatch. They just keep taking it off, then wondering why nobody recognises them, even in an 8:30 break with three people trying.
