# Chapter 47: More doing, less discussing

_Part 4_

[CHAPTER INTRO]
The best teams spend more time doing the work and less time discussing it, selling it, and keeping everyone up to speed. Meetings multiply when handoffs multiply. The alignment tax is real. People forget 70% of meeting content within 24 hours anyway, then fill the gaps with invented reconstructions. The goal isn't fewer meetings for the sake of it. It's more time in the work and with customers.


[SUPPORTING NUGGETS]


Source: Ruben Hassid, "You forgot 70% of yesterday's meeting.", 2026-01-25
Claim: People forget 70% of meeting content within 24 hours due to the Ebbinghaus effect, and their brains fill memory gaps with invented reconstructions.
Full argument: The Ebbinghaus effect describes how human memory rapidly degrades after information exposure. In meetings, this creates a dual problem: not only do participants forget most content within a day, but their brains actively reconstruct missing information using fragments, assumptions, and expectations. This means the meeting people remember is fundamentally different from what actually occurred, leading to false shared memories and misaligned execution.
Evidence: Referenced as 'the Ebbinghaus effect'. Author provides specific example of client team spending three weeks building a feature their VP 'asked for' in a meeting, which transcript evidence proved she never requested, yet four people would have sworn she did.
Key quote: "Your memory is (always) a fan fiction you wrote after the meeting."


Source: Marketing Insider, "Alignment Is Overrated. Authority Is Underrated.", 2026-01-27
Claim: The fastest way to reduce organizational friction is answering three explicit questions: What decision is being made? Who owns it? Who is consulted vs informed?
Full argument: Instead of calling more alignment meetings, teams should focus on decision clarity. When these three questions have clear answers, alignment happens naturally. When they don't, alignment becomes the work itself rather than the outcome. This creates a framework where authority is operationalized rather than dependent on personality, tenure, or escalation.
Key quote: "When those answers are clear, alignment happens naturally. When they aren't, alignment becomes the work."










Dashboards lie


My mornings are mostly me bargaining with the snooze button like it’s a hostage situation. By the time I’ve made tea, I’ve already “quick checked” Slack three times and learned nothing except that people can type at 6:47am. I tell myself I’m being productive. I’m not. Then I put on headphones and listen to a customer call.
At Miro I blocked twenty minutes every morning for Gong. Not the summaries, not the neat little insights someone had already rounded off. The actual recordings. Insights showed up in sighs. In pauses. In jokes customers didn’t think we’d hear. It wasn’t research. It felt more like keeping your ear tuned, the way you stay decent at a language by speaking it a bit every day.
Dashboards don’t do that job. Dashboards are polite. They tell you what happened after it’s already happened, and they do it in a font that makes everything look under control. A recording is messy. Someone is trying to explain their day, and you can hear the extra work they’re doing to make your product fit. You also hear the words they reach for when they’re not performing for a survey. After enough calls, you start spotting the gap between what you’ve been saying and what they actually care about, and it becomes hard to write another line of copy that sounds good but means nothing.
The main thing that changed wasn’t a single magical insight. It was my tolerance for secondhand confidence. Once you’ve heard customers wrestle with a workflow in real time, a glossy internal narrative starts to sound like it’s been written by a committee in a windowless room. You still need the deck, unfortunately, but you stop believing the deck is the truth.
I’d seen a more physical version of this at O2. The marketing team worked actual shifts in stores. Not “spent time” in stores, not a research safari with a lanyard and a clipboard. You worked. You talked to people who were annoyed, confused, in a rush, or just trying to get their phone to stop doing something weird. You handled complaints that had nothing to do with whatever campaign was being celebrated upstairs. You watched someone misunderstand a basic step and blame themselves for it, and you realised how little your lovely messaging helped them in that moment.
It did something to the team. Personas stopped being laminated characters and became real humans with names, habits, and specific frustrations. Briefs tightened because there was less room for waffle when you’d been face to face with the problem. Messaging sharpened because you could hear what landed and what got you the blank stare. Proximity stopped being a research function. It became culture.
Then there was Andre.
Andre Khusid ran Miro as it grew into a 1,600 person company with around 250,000 customers, and he was still on customer calls. Miro was pushing hard on AI, building towards products where the output can vary, and you’d expect the CEO to be living in strategy papers and launch plans. Instead, a lot of his time was spent demoing prototypes, listening to workflows, validating direction. Not as theatre. As a way of staying close enough to reality to make bets without kidding himself.
His reasoning was simple. AI is non deterministic. Outputs vary. You cannot test something once and ship it like traditional software. To make it useful, you need to understand a customer’s workflow deeply enough to know when the variation is fine and when it breaks the job. That understanding does not survive translation. It gets sanded down somewhere between the call, the summary, and the slide. As Andre put it, “You need to get that firsthand insight when you bet the whole company on the next horizon.”
This is where a lot of marketing teams get caught out right now. AI makes it easy to produce confident work from thin understanding. The output looks polished. The words are plausible. Everyone moves faster, and nobody can quite explain what they’re anchored to.
AI can scale understanding. But it can’t fake it.
If you’ve listened to hundreds of calls, a tool that clusters themes across transcripts and tickets is a pattern recogniser. It helps you see what you’d miss. If you haven’t done the listening, the same tool is just remixing marketing folklore with a straight face. It doesn’t replace proximity. It punishes the people who skip it.
Most teams aren’t lazy. They’re busy producing outputs. Insight arrives quarterly, filtered through layers of research, analysis, and internal spin, and by the time it reaches a decision it has been averaged into something safe. Slide obsessed, not customer obsessed. You can feel the beige settling in.
The fix is not a bigger research project. It’s a habit, backed by a system that keeps raw customer reality flowing into the work. Calls, support tickets, feedback forms, the messy stuff. Patterns can surface automatically, sure, but they need to land where decisions happen, in the brief, in the roadmap conversation, in the pricing debate, not in a deck nobody opens. And when you can, you attach commercial weight to it. “Open API requested by X, Y, Z” becomes “Revenue potential: $304K,” and suddenly everyone stops pretending they didn’t see it.
Keep it blunt and doable. Three to five call listens per marketer per week, minimum, not just the one person with “insights” in their title. A bit of manual tagging before you automate anything, so you learn what important actually sounds like. Track proximity like a real metric, not for performative bragging, just to answer a basic question: how many customer voices did we hear this week, and where did they show up in what we shipped.
Twenty minutes in the morning doesn’t look like strategy. It looks like someone with headphones on, listening to a stranger hesitate, and realising the work they were about to do is not the work that’s needed.








The listening habit


[CHAPTER INTRO]
You have hundreds of hours of untapped customer conversations. Mine them. Build a weekly listening habit. Not the summaries, not the insights someone tidied up. The actual calls. You hear the sighs, the pauses, the frustration. Dashboards tell you what happened after it already happened. Recordings are messy. That's the point.


[SUPPORTING NUGGETS]
(The existing Dashboards lie chapter and the Miro/Andre Khusid material already covers this well.)








3: Hire for curiosity




The fox test


[CHAPTER INTRO]
When interviewing, listen for what they got curious about that nobody asked them to explore. The foxes are self-critical, eclectic thinkers who update their beliefs when evidence pushes back. They don't wait to be trained. They train themselves. In an interview, ask what they've been experimenting with lately. The ones who light up have the thing you can't teach.


[SUPPORTING NUGGETS]


Source: Philip Tetlock
Claim: Political forecasters who rely more on observation than theory and have multiple unrelated ideas (foxes) outperform those with big unifying theories (hedgehogs).
Evidence: Analysis of political forecaster characteristics found better forecasters were less attached to big unifying ideas and relied more on observation than theory.
Key quote: "foxes were better forecasters"


Source: AI Adopters Club, Kamil Banc, "Good at your job but bad at AI?", 2026-01-28
Claim: High-performing AI users demonstrate 'Theory of Mind', they set context, fill information gaps, and treat bad outputs as diagnostic information rather than just rephrasing requests.
Full argument: The research identified three specific behaviors that separate successful AI collaborators: providing background context about their role and objectives, proactively sharing knowledge the AI lacks (company context, constraints, previous attempts), and analyzing failed outputs to understand why the AI missed rather than just trying different wording. This 'Theory of Mind' approach treats the AI as a collaborator that needs proper briefing rather than a search engine that needs better keywords.
Key quote: "They treated bad answers as information."




Pause before you hire
Last Tuesday I sat down with a mug of tea at 7:12, laptop open, chapter doc staring back at me, and all I could think was, where did I see that Tropicana thing. I’d even underlined it in my head, which is not a filing system. That’s the bit. Then you realise the work is not the reading, it’s the rummaging after. And that rummaging is where the weeks go when the job is meant to be “just write the chapter.”
When I wrote my first book, a big chunk of it was basically admin with better PR. Read an article, watch a talk, hear a quote, think, that’s useful, then try to put it somewhere I would actually find again. I had folders. I had notes. I had little half-sentences in random apps that made sense for about four hours. Three weeks later I’d be back at the same problem, vaguely remembering the shape of the story, not the link, not the source, not the wording that made it land.
This time I did something different. Over a weekend I built a system with Claude Code. Not a spec, not a project plan, just me describing what I wanted in conversation until it was clear enough for an AI to make real. It monitors 11 YouTube channels and my newsletter inbox. Three times a week it watches the new episodes, reads the new emails, pulls out anything that fits the chapters I’m writing, and files it as structured notes. Nearly 5,000 little research nuggets sitting there now, tagged and waiting. It runs on its own. No prompting. The hours I used to spend reading and filing now happen while I sleep.
I’m not telling you this because I want you to build a research robot and start a publishing side hustle. I’m telling you because it’s the same shape as half the decisions we make in marketing teams, and we keep acting like the only two options are “someone does it” or “we hire someone.” There’s a third option, the boring one, the one that feels like cheating when it works. Build something that does the job, then let it run.
Think about the recurring tasks in your team that are never bad enough to hire for, but somehow show up every week like clockwork. Meeting prep. Competitive monitoring. Reporting that involves copying numbers from one place to another, then arguing about whose spreadsheet is “the latest.” Pulling updates out of six different tools and turning them into one tidy summary for a Monday morning call. Nobody gets a headcount approved for that, so it becomes a tax we all quietly pay.
And when we do hire, or bring in an agency, it’s rarely the task that costs you. It’s everything around it. The brief that takes two hours because you’re trying to translate what you mean into something someone else can follow. The waiting. The first draft that is fine, but not quite it. The “that’s not what I meant,” which is always true and never helpful. The rebriefing. The waiting again. At some point you start measuring time in feedback loops.
A system that runs while you sleep has none of that. No handover. No calendar tennis. No “just circling back” email that makes you want to throw the laptop into the canal. It just does the thing every Monday, Wednesday, Friday, whether anyone is having a good week or not.
This is what “four beats fifty” looks like in practice. Not squeezing people harder. Not pretending we can do more with less through sheer grit. Just making certain bits of work disappear, the bits that exist only because humans are terrible at remembering where they put things.
So before you add headcount, before you commission someone for a task that repeats, sit there for a minute and ask the annoying question. Can we build something that does this while we’re asleep, and if we can, why are we still paying for the waiting?


4: Create generalists




The hedgehog problem


[CHAPTER INTRO]
The specialists who can't adapt get stuck. Not because they're bad at their jobs, but because their jobs got smaller. AI accelerates this. When the tools can handle production, value shifts to judgement. Judgement doesn't live in a single channel. The fix isn't to fire specialists. It's to retrain them. Give them permission to learn adjacent skills.


[SUPPORTING NUGGETS]


Source: NA, "Marc Andreessen: The real AI boom hasn't even started yet", 2026-01-29
Claim: The additive effect of being good at two skills is more than double; being good at three things is more than triple, creating super-relevant specialists in domain combinations.
Full argument: Scott Adams used to say he could have been a pretty good cartoonist or pretty good at business, but being a cartoonist who understood business made him spectacularly great at making Dilbert. Even the world's best cartoonist who didn't understand business could never have written Dilbert, and the world's best business people who didn't know cartoons couldn't have done it either. The additive effect of being good at two things is more than double, the additive effect of being good at three things is more than triple, because you become a super relevant specialist in the combination of the domains.
Key quote: "The additive effect of being good at two things is like more than double"


Source: Dan Koe, "How to think like a strategic genius (5d thinking)", 2026-01-27
Claim: Smart people with domain expertise often perform worse in other life areas because they try to reduce everything to problems within their specialty, creating 'horizontal advancement but vertical stuckness'.
Full argument: High IQ individuals frequently fall into obvious traps because they become experts in one domain but fail to develop cognitive sophistication across multiple areas. A businessman may have wealth but be unhappy, a creative may produce beautiful work but can't monetize it, because they only know how to think within their specialty bubble. This creates a phenomenon where people are 'smart but dumb', they have extensive horizontal knowledge in one line but lack the vertical development to see outside their expertise and solve broader life problems.
Key quote: "Smart thinking is reductionistic. Experts in one domain, like business, try to reduce everything to a 'strategy' problem"








5: Find the ones with taste




AI can't give you a good idea


[CHAPTER INTRO]
AI can give you variations. It can help you execute. What it can't do is tell you which idea is worth pursuing. Someone who has done enough work knows what good looks like. They can feel when something is off. You hire for taste by looking at work. What have they made? What did they kill that looked fine but felt wrong?


[SUPPORTING NUGGETS]


Source: Marketing Against the Grain, "This Video Proves AI Generated Images are Dying", 2026-01-13
Claim: AI is most effective for people with deep domain expertise, making craft skills more important than ever.
Full argument: AI to me is incredible for people with deep domain expertise. So it actually means your expertise and your craft making skills are going to be more important than ever because when you have those things you can then use AI to do more of it and better versions of it, right? So you see a lot of the content being created on AI and a lot of the slop is being created by people who are just having fun, right? They are not trying to do something transformational with it.
Key quote: "your expertise and your craft making skills are going to be more important than ever"


Source: Marketing Against the Grain, "Marketing is Already Dead, You Just Don't Know It", 2026-01-20
Claim: AI should make marketers into craftspeople who can create more valuable content, not automate the creation itself.
Full argument: I would say marketers like PJ is a good example he is a true uh domain expert on that video like he crafts incredible videos that are engaging that you want to watch but he uses AI tools to be able to do that in a shorter amount of time so he craft more things. He can craft more things because it costs less. He takes less time. He's less dependent upon other people. He's more autonomous. And so he can actually really craft more things of value for his customers.
Key quote: "I would never recommend having an AI autonomously create content on your behalf"


Source: Ethan Mollick from One Useful Thing, "Management as AI superpower", 2026-01-27
Claim: Subject matter expertise becomes the critical differentiator in AI delegation because experts know what instructions to give, can better identify when something goes wrong, and are more effective at correction.
Full argument: Three factors make AI delegation more successful: giving better instructions with clear goals, getting better at evaluation and feedback to reduce iteration cycles, and making it easier to evaluate AI output quality without extensive time investment. All of these are improved by domain expertise. Experts have frameworks from their training and experience that translate directly into effective AI prompts, while also having the judgment to recognize quality outputs and provide corrective guidance.
Key quote: "The skills that are so often dismissed as 'soft' turned out to be the hard ones"








6: Build a team that asks why




Kill confident nonsense


[CHAPTER INTRO]
AI produces polished output. Polished output feels finished. Finished output doesn't get questioned. This is the new failure mode. The pause is a skill. It can be taught. It can be rewarded. Make "where did this come from?" a normal question. When someone kills a plan that looked good because they found a hole, celebrate it.


[SUPPORTING NUGGETS]


Source: Marketing Against the Grain, "This Video Proves AI Generated Images are Dying", 2026-01-13
Claim: AI amplifies existing ignorance rather than fixing knowledge gaps in marketing.
Full argument: If you're ignorant on a subject without AI, then you're 10x ignorant on that subject with AI, right? Like AI is just going to exponentially multiply your ignorance. It's not going to fix it. And there are a lot of people who are like, 'Oh, I can pretend or show that I know something or can do something I'm really not incapable of doing with AI.' And that's really what generates AI slop, right?
Key quote: "AI is just going to exponentially multiply your ignorance. It's not going to fix it"


Source: Christopher S. Penn from Almost Timely Newsletter, "Almost Timely News: Demonstrating the Art of the Possible in AI", 2026-01-18
Claim: The '3C skills' (creative, critical, and contextual thinking) are essential for effective AI use and provide competitive advantage.
Evidence: Author explains: 'Creative thinking means you have the ideas in the first place. Critical thinking means you can evaluate what the machine produces and know when it's wrong. Contextual thinking means you know where all the data lives, what's relevant, what the real-world constraints are.'
Key quote: "Without those three skills, you're just pushing buttons and hoping for the best"


Source: Lenny's Podcast, "Why most AI products fail: Lessons from 50+ AI deployments at OpenAI, Google & Amazon", 2026-01-11
Claim: Air Canada's AI agent hallucinated a refund policy that became legally binding.
Setup: Air Canada was using an AI agent for customer support that had access to their policies and procedures.
What happened: I think Air Canada had this thing where um one of their agents predicted or hallucinated a policy um for a refund which was not part of their original playbook and they had to go by it because legal stuff.
Why it matters: This shows the real business and legal risks of giving AI agents too much autonomy too quickly, hallucinated policies can become legally binding commitments that companies have to honor.
Key quote: "they had to go by it because legal stuff"




---




The robot is the grown-up in the room now
My mate joined a “quick catch up” from a hotel lobby, wearing a shirt he’d only ironed at the front, because that’s what the webcam sees. The meeting ran long enough for him to finish a yoghurt, rinse the tiny spoon, come back, and still hear “we’ll circle back” said like it was a plan. Nobody sounded angry, which is how you know it’ll happen again. 
That’s how we roll. Most meetings end and everyone just moves on. Nobody says, “you avoided the decision again,” because it’s awkward. 
A woman in Zapier used AI to change this culture.Courtney Hickey set up a simple loop after meetings. The call ends, the transcript lands, and a bot sends each person a Slack message with a bit of feedback. Not “here are your tasks”, more “here’s how you showed up”, measured against the stuff the company already says it cares about, like their values, their decision norms, and the Five Dysfunctions framework. She showed it to Wade, their CEO, and his only request was basically, make it tougher. 
A team can say “we want better meetings” for years and it stays vague because nobody wants to be the hall monitor. But when the feedback arrives every time, fast, in the same format, it turns into a habit. People start to notice the boring patterns, who talks first, who never talks, where the decision slides into “we’ll revisit”, how often conflict gets politely parked.
It only runs on meetings longer than ten minutes, only for employees, only when there’s enough transcript to judge. The DM stays short, one or two things to work on, one or two things to try next time. If it’s longer than that, nobody reads it, they just park it with the other tabs.
It also fixes a social problem most teams pretend they do not have. Feedback is easier when you have history. If you have worked with someone for five years, you can say, “you should have spoken up there”, and it lands. If you are new, you keep quiet even when you are right, because you do not want to be “difficult” in week three. Courtney’s phrase was that AI feedback “takes spit off the ball”. Same point, less sting, and because everyone gets it, it does not feel like a personal call-out.
It will still miss things. Even in your notes, she says leaders change fast and old decisions hang around longer than they should. So you use it as a prompt, not a verdict. The useful bit is the repetition. If feedback is expected after a meeting, and it arrives in the same way every time, people stop treating it like a drama and start treating it like part of the job








7: Restructure for speed




Four beats fifty


[CHAPTER INTRO]
A team of 4-6 empowered builders will outexecute a 50-person org. OpenAI built Sora Android with 4 engineers in 28 days. AI-enabled marketers operate at 10x scale, not 10% improvement. The bottleneck is no longer "can we make this?" It's "should we make this?" That question gets answered faster by a small team with context than by a large team with process.


[SUPPORTING NUGGETS]


Source: Peter Yang, "25 Things I Believe In To Build Great Products in 12 Minutes", 2026-01-07
Claim: A team of four to six full stack builders will out execute a 50 person org any day of the week.
Full argument: Yang argues that 'small teams ship faster. A team of four to six full stack builders who are empowered to co-create with users and learn from failure will out execute a 50 person org any day of the week. The key word here is empowered. If you hire a team of A players, you have to give them the autonomy to iterate relentlessly with real users.'
Key quote: "A team of four to six full stack builders who are empowered... will out execute a 50 person org any day of the week"


Source: How I AI, "The power user's guide to Codex | Alexander Embiricos (product lead)", 2026-01-12
Claim: OpenAI built the Sora Android app with 4 engineers in 28 days using Codex and it immediately became the #1 app in the app store.
Full argument: We used Codex to build a sore app for Android in 28 days and it immediately became the number one app in the app store. So you know four engineers 28 days number one app in the app store and it's not a trivial app that I was super impressed by the speed as I was watching this team go. With coding agents it doesn't get easier but you just move way faster.
Key quote: "four engineers 28 days number one app in the app store"


Source: Marketing Against the Grain, "Our Top 5 AI Tools for Marketing in 2026 (AI Marketing Essentials)", 2026-01-06
Claim: AI-enabled marketers with agentic workflows will operate at 10x scale compared to traditional marketers, not just 10% improvement.
Full argument: If you take two marketeteers in 2026, one understands how to build agentic workflows and has built an army of agents to do a ton of work. So they show up as an actual team, a marketing team or a traditional marketer that's trying to compete with them with no one, right? Who wins that? The AI enabled marketer. Even if you're really awesome, it's just you can't compete if somebody's operating at not like 10% more scale, but like 10 times more scale, right? And that's the delta that is going to start happening.
Key quote: "Even if you're really awesome, it's just you can't compete if somebody's operating at not like 10 times more scale"










A Growth Marketing team of one


I was on my phone last week, and ended up reading a doc Anthropic shared about how they use Claude Code. 
Naturally, I took a proper snoop through the bit on Growth Marketing. They use a Figma plugin with Claude Code to generate up to 100 Meta ad variations in about half a second. They feed a CSV with hundreds of ads into a system that rewrites the weak ones. 
I say ‘they’ but it’s just their growth marketing team is a non-technical team of one. One lad, no engineering background, still expected to ship.
What are they using Claude Code for, in plain terms? Making more ads, faster.
They’ve got a workflow where they drop in a CSV of existing ads with performance metrics. The system spots the underperformers and generates new variations at scale. Hundreds in minutes. .
They break the work into two specialised sub agents, one for headlines, one for descriptions. Their advice in the doc is straight, “Break complex workflows into specialized sub agents… this makes debugging easier and improves output quality.” It’s not deep, it’s just practical, which is usually what scales.
Their Figma plugin has reduced “hours of copy-pasting to half a second per batch.” 
They also built an MCP server integrated with the Meta Ads API for campaign analytics. So the same setup that helps produce ads also pulls performance data into the workflow. 
The numbers they share are the kind that make you pay attention. Ad copy creation goes from two hours to fifteen minutes. Creative output goes up 10x. That’s not a nice little improvement.
---




Collapse the handoffs


[CHAPTER INTRO]
Every handoff is a tax. Information gets lost. Context gets simplified. The fix isn't better briefs. The fix is fewer handoffs. When one person can do positioning, messaging, and a first draft of the landing page, you don't need three meetings to align three people. AI makes this possible because it gives people range.


[SUPPORTING NUGGETS]
(Use the existing Part 1 material about the relay race model being sidelined.)








8: Stay in the work




The delegation trap


[CHAPTER INTRO]
CEOs write the AI memo, announce the initiative, then delegate. The memo goes to exec team, to director, to manager, to IC. That poor IC is left figuring it out for the whole company. The CEOs who get AI working stay in the work. Not doing everything, but close enough to feel where it breaks.


[SUPPORTING NUGGETS]


Source: How I AI, "Zapier's CEO shares his personal AI stack | Wade Foster", 2026-01-05
Claim: CEOs commonly fall into a 'delegation trap' with AI adoption where they write memos but don't provide organizational support for implementation.
Full argument: I see a lot of CEOs fall to the delegation trap. They write the AI memo. They say, 'Hey, we're going to go do this.' And then they don't do anything else. They ask their exec team, who ask a director on their team, who ask a manager on their team, who ask an IC on the team, and then that poor IC is like, 'Am I figuring this out for the whole company?' It's like, 'Do you think that's going to go well for that person or for your org?' And it's like, 'No, not really.'
Key quote: "I see a lot of CEOs fall to the delegation trap. They write the AI memo. They say, 'Hey, we're going to go do this.' And then they don't do anything else."


Source: Category Pirates, "Why your team still doesn't 'get' category design (and how to fix it)", 2026-01-28
Claim: Leaders become growth bottlenecks when strategic thinking stays concentrated in their heads rather than distributed across teams.
Full argument: When only the leader understands category design or strategic frameworks, every POV conversation, strategic decision, and customer interaction requiring different thinking has to run through them. This creates a bandwidth limitation where the company's vision and growth can only move as fast as the leader can personally handle decisions. Distributing this thinking capability allows teams to operate independently, have customer conversations without the leader present, and push back on best practices autonomously.
Key quote: "You become the bottleneck for your own company's growth."








Build it in front of them


[REFERENCE: See Part 3 for the full chapter. Key points: In 60 minutes at Smurfit UCD, built positioning, messaging framework, blog posts, LinkedIn ads, a Google Slides deck, and a website live in front of postgrads. The gap between marketers who create and marketers who consume is the story of this era. Elena Verna at Lovable: specs are always accompanied by a working prototype. Building does a job that meetings can't do.]








9: Build new agency models








The new split


[CHAPTER INTRO]
The question isn't "agencies or in-house". It's "which bits where". Strategy and planning might belong closer to you. Creative firepower might stay outside. Production is shifting as AI means smaller teams can do more. Ask: what do we need to own, and what do we need to access?


[SUPPORTING NUGGETS]
(Search for P&G/Pritchard agency model content, or reference the existing industry knowledge.)








10: BE BRAVE




The remarkable advantage


[CHAPTER INTRO]
When average execution is free, average execution is worthless. The algorithms filter out the middle. The safe choice is now the dangerous choice. Challenger brands outperform incumbents with AI because they have no sacred cows. Be brave. Try the weird thing. The cost of failure is lower than ever. The cost of being boring is higher.


[SUPPORTING NUGGETS]


Source: Thats What I Call Marketing, "S5 Ep3: The Tensions Every Brand CEO Has to Manage", 2026-01-27
Claim: Tropicana's purely emotional flying fruits ad tested poorly but became a sales success.
Setup: Bazini's team at Pepsi created a Tropicana ad that was simply flying fruits, beautiful macro photos of gorgeous fruits with Louis Armstrong's 'What a Wonderful World' playing. It was purely emotional with no message or information.
What happened: The ad tested poorly, results came back saying 'consumer don't understand the message' and 'consumer don't walk away with information.' Bazini responded 'Well, yeah, there is no message' and 'No, there is no information. It was purely about glorifying the fruit and the juice.' Despite all red test results, they put the ad on air anyway. The sales flew off and it was a big success.
Why it matters: It taught Bazini to take advertising tests with a grain of salt and reinforced that everything is art and science. Tests can help improve ads but can't predict business impact, especially for emotional advertising.
Key quote: "best decision of my life. The sales flew off"


Source: Beth Bentley, PATTERN RECOGNITION by tomorrowism.co, "The Eccentric is SO back", 2026-01-21
Claim: The amount of eccentricity in a society directly correlates with its levels of courage and creative capacity.
Full argument: John Stuart Mill theorized that eccentric behavior serves as an indicator of a society's overall bravery and willingness to challenge norms. When people feel safe to express unconventional ideas and behaviors, it signals that the broader culture tolerates dissent and values innovation. Eccentrics act as canaries in the coal mine for creative freedom, their presence indicates that a society hasn't become too rigid or conformist.
Key quote: "the amount of eccentricity in a society is proportional to its levels of courage"


Source: Level Up Newsletter, "How to Take the Right Risks", 2026-01-22
Claim: Professional risk-taking differs from gambling through calculated probability assessment over time horizons.
Full argument: The distinction between brave and stupid decisions lies not in individual outcomes but in the systematic approach to risk evaluation. Professional poker players don't win every hand, but their decision framework ensures positive expected value over extended periods. Similarly, business leaders should evaluate risks based on long-term probability of success rather than guaranteed outcomes.
Key quote: "Successful people take risks; they don't gamble."








Getting attention from robots


Last week I asked an AI a boring question about a boring feature, which is usually how the odd stuff sneaks in. I typed it out in a full sentence, hit enter, and watched it skim the internet like it had somewhere else to be. It didn’t care about the brand story or the lovely homepage video, it lifted one line from a help article and one line from a third-party page, then handed them back to me like receipts. That’s the bit.
Then you read it and realise what’s changed. You’re not only writing for the person with a coffee in their hand, you’re writing for the machine that’s scanning for something it can take.
Humans still do the human stuff. We want to feel safe buying something. We want to like the look of it. We want to believe we’re not idiots for spending the money.
Machines do something you can actually see. They extract. They look for a claim, a spec, a comparison, a line that answers the question cleanly, and they pull it forward. They don’t get a warm feeling from your positioning. They get a piece of information they can reuse.
Neither replaces the other. If you only talk to the machine, you’ll sound like an instruction manual that’s trying to flirt. If you only talk to the human, you can be invisible at the exact moment someone asks, “which one does X, Y, and Z.”
Traffic from LLMs is climbing fast. A lot of teams are seeing it grow hard year on year, often doubling, but it’s still a fraction of traditional search in most categories.
The bigger shift is how it works.
In traditional SEO, being broadly trusted helped. Links, mentions, decent coverage across the web, it all added up.
LLM answers are pickier. The model is trying to answer one question. It grabs bits it can lift, a clear sentence, a spec, a “yes, but” limitation, and it stitches an answer together. When it shows citations, it tends to lean on the same kinds of shelves for that question, docs, help centres, big review sites, Wikipedia, forums, comparison posts.
So “we’re well known” helps less than you’d like. “We’re named in the places the model keeps quoting for the question we care about” helps more.
A simple test: ask the question you want to win, like “Does [Product] work with Stripe?” If the answer includes sources, treat those URLs as key shelves for that question. Make sure your product is described there in one plain sentence, with the real limitation included, and keep it current. It won’t guarantee you win, but it moves you from missing to available.
John Hegarty is 81 now. His Levi’s work in the mid-1980s is what got me excited about marketing as a career, which is a sentence that makes me feel old in a very particular way.
When he talks about where this is going, it’s worth listening, because he’s not doing the usual panic. He puts it in plain terms.
“Your communication has got to have something in it that AI can take.”
“AI can't take ‘oh, I felt good.’ Feeling good is how I get to me. But how I get to AI is that I put something within my story that AI goes, I can take that. I understand that.”
He also points out BBH was always “a very old-fashioned advertising agency” because they believed in product demonstration. Double-stitch for extra strength. Audi four-wheel drive, better handling.
His argument is that this becomes modern again. When AI is processing your brand, it needs concrete, demonstrable claims. “Audi four-wheel drive performance, better handling on the road” is something an algorithm can work with. Vague emotional positioning isn’t.
The man whose work made me want the job is still telling the rest of us to stop being foggy and start being specific.
The long tail is longer now. People don’t ask in keyword fragments, they ask in proper sentences.
“I want a website builder with SEO features, Stripe integration, and design portfolio support.”
Nobody typed that into Google for years. Someone is asking it now, and they expect one answer, not a list of links.
This is where things get unfair in a useful way. If you are the only product that genuinely fits a very specific question, you can win that query cleanly. Not with a clever ad, but with the boring truth said clearly.
It also changes what counts as “marketing” work.
Your help centre becomes a discovery asset. Your product pages stop being brochures and start being evidence. Your feature descriptions, compatibility notes, limitations, pricing edge cases, the stuff you normally hide in a FAQ, it becomes raw material the machine can lift.
And the places that get cited matter more than general noise. You need to know which URLs show up when someone asks the question you care about, then make sure you’re mentioned there in the right sentence.
Write down the ten questions you actually want to be the answer to. Real questions. “Does it integrate with X?”, “Will it work for a portfolio?”, “Can I take payments without an accountant?”
Ask them in the tools your customers use, then note what gets quoted or linked.
Look at your own pages and ask, honestly, do we state the answer in a way a machine can lift without guessing?
If the answer is no, you don’t need a new channel. You need to rewrite what’s already there.
This isn’t a new set of skills. It’s the old skills, with less room to waffle.
Know what your product actually does. Be able to articulate it clearly. Make concrete claims that can be extracted and checked.
Hegarty called BBH “old-fashioned” for believing in product demonstration. Turns out old-fashioned is modern again, which is either comforting or depressing depending on how many meetings you’ve had this week.
Agentic AI, where your assistant shops on your behalf, is coming. When it lands properly, the “two audiences” thing gets sharper, because the machine won’t just recommend, it’ll choose.
But mass adoption feels like years, not months. There’s time to build the muscle. Learn what gets cited. Fix the pages you’ve neglected. Get serious about making claims you can stand over.
The people who do the reps now will look annoyingly calm later.
I went back to that answer the AI gave me and clicked the sources, out of nosiness more than anything. The brand homepage wasn’t there. The glossy video wasn’t there. It was the help article with the one clean sentence, plus a third-party page that happened to say the same thing in plain language.
It didn’t feel like marketing in the moment. It felt like being marked.
